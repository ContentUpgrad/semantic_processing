{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fitting-soccer",
   "metadata": {},
   "source": [
    "## The Problem: Large Movie Dataset Review\n",
    "### Classify movie reviews from IMDB into positive or negative sentiment.\n",
    "### Download the dataset [here](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coordinated-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tejaswiniallikanti/miniconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, Dense, Input, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-washer",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "welsh-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75000 files belonging to 3 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7bfa2a64d8c1>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  xts['text'] = xts['text'].map(lambda x: x.decode())\n"
     ]
    }
   ],
   "source": [
    "# Importing & preprocessing the dataset\n",
    "\n",
    "train_ds = text_dataset_from_directory('../Distributional Semantics/data/aclImdb/train')\n",
    "test_ds = text_dataset_from_directory('../Distributional Semantics/data/aclImdb/test')\n",
    "\n",
    "dfTrain = pd.DataFrame(train_ds.unbatch().as_numpy_iterator(), columns=['text', 'label'])\n",
    "dfTest = pd.DataFrame(test_ds.unbatch().as_numpy_iterator(), columns=['text', 'label'])\n",
    "_, xts = train_test_split(dfTest, stratify=dfTest['label'], test_size=0.25)\n",
    "\n",
    "dfTrain['text'] = dfTrain['text'].map(lambda x: x.decode())\n",
    "xts['text'] = xts['text'].map(lambda x: x.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "right-visiting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72396</th>\n",
       "      <td>For the first half of the film, as it actually attempts to make some sort of a story involving the theft of the Pink Panther, this movie almost works. However, when there are no more outtakes, or ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>In Manhattan, the American middle class Jim Blandings (Cary Grant) lives with his wife Muriel (Myrna Loy) and two teenage daughters in a four bedroom and one bathroom only leased apartment. Jim wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16953</th>\n",
       "      <td>Here was a director and a writer who knew that they had a real story that needed a minimum amount of added-on work to make a fine movie. The time passing early on being marked by the fighter-jets ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24931</th>\n",
       "      <td>I want to state first that I am a Christian (and that I do work in the film and TV industry) so I understand what it is like to work on a feature length film so props to the filmmakers in that reg...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23975</th>\n",
       "      <td>The King of Masks is a beautifully told story that pits the familial gender preference towards males against human preference for love and companionship. Set in 1930s China during a time of floods...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          text  \\\n",
       "72396  For the first half of the film, as it actually attempts to make some sort of a story involving the theft of the Pink Panther, this movie almost works. However, when there are no more outtakes, or ...   \n",
       "1353   In Manhattan, the American middle class Jim Blandings (Cary Grant) lives with his wife Muriel (Myrna Loy) and two teenage daughters in a four bedroom and one bathroom only leased apartment. Jim wo...   \n",
       "16953  Here was a director and a writer who knew that they had a real story that needed a minimum amount of added-on work to make a fine movie. The time passing early on being marked by the fighter-jets ...   \n",
       "24931  I want to state first that I am a Christian (and that I do work in the film and TV industry) so I understand what it is like to work on a feature length film so props to the filmmakers in that reg...   \n",
       "23975  The King of Masks is a beautifully told story that pits the familial gender preference towards males against human preference for love and companionship. Set in 1930s China during a time of floods...   \n",
       "\n",
       "       label  \n",
       "72396      2  \n",
       "1353       1  \n",
       "16953      2  \n",
       "24931      0  \n",
       "23975      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "dfTrain.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "japanese-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a great example of \"film noir,\" as every scene has some sort of shadow pattern on the wall, the floor, the faces. All shots are done with key light on the faces. The patterns suggest \"jail,\" \"locked up,\" \"flight\" (as in a train track), \"trapped,\" (as in a cobweb), and others. There isn't one scene that doesn't have a shadow in it! Even the day time sequences. And the actors that had great careers: Stanwyck, Gary Merrill, Claude Akins, even Jesse (the original maytag repairman) White, and, of course, George Sanders, who plays a \"deNazified\" ex-Nazi. Whew! Great stuff.\n"
     ]
    }
   ],
   "source": [
    "print(dfTrain.loc[0, 'text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-vault",
   "metadata": {},
   "source": [
    "## Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "future-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153845 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dfTrain['text'].tolist())\n",
    "train_sequences = tokenizer.texts_to_sequences(dfTrain['text'].tolist())\n",
    "test_sequences = tokenizer.texts_to_sequences(xts['text'].tolist())\n",
    "\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "headed-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 6, 3, 80, 501, 4, 19, 1460, 14, 172, 129, 44, 46, 435, 4, 2831, 6273, 20, 1, 1600, 1, 1808, 1, 1465, 29, 684, 23, 224, 15, 1296, 627, 20, 1, 1465, 1, 10593, 1478, 2618, 3008, 53, 2762, 14, 8, 3, 1233, 1441, 2387, 14, 8, 3, 29382, 2, 395, 47, 215, 27, 129, 12, 148, 25, 3, 2831, 8, 9, 56, 1, 250, 55, 814, 2, 1, 156, 12, 67, 80, 3704, 3755, 1964, 14386, 4144, 22703, 56, 3838, 1, 207, 58547, 29383, 461, 2, 4, 267, 745, 7188, 34, 284, 3, 87409, 1180, 2292, 15749, 80, 529]\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "oriental-copper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'great', 'example', 'of', 'film', 'noir', 'as', 'every', 'scene', 'has', 'some', 'sort', 'of', 'shadow', 'pattern', 'on', 'the', 'wall', 'the', 'floor', 'the', 'faces', 'all', 'shots', 'are', 'done', 'with', 'key', 'light', 'on', 'the', 'faces', 'the', 'patterns', 'suggest', 'jail', 'locked', 'up', 'flight', 'as', 'in', 'a', 'train', 'track', 'trapped', 'as', 'in', 'a', 'cobweb', 'and', 'others', 'there', \"isn't\", 'one', 'scene', 'that', \"doesn't\", 'have', 'a', 'shadow', 'in', 'it', 'even', 'the', 'day', 'time', 'sequences', 'and', 'the', 'actors', 'that', 'had', 'great', 'careers', 'stanwyck', 'gary', 'merrill', 'claude', 'akins', 'even', 'jesse', 'the', 'original', 'maytag', 'repairman', 'white', 'and', 'of', 'course', 'george', 'sanders', 'who', 'plays', 'a', 'denazified', 'ex', 'nazi', 'whew', 'great', 'stuff']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.index_word[k] for k in train_sequences[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "subjective-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = max([max(map(len, train_sequences)), max(map(len, test_sequences))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "promising-rochester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2493"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "surgical-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sexual-convenience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', 'ina', 'garden', 'rocks', 'her', 'cooking', 'is', 'simple', 'tasty', 'and', 'fun', 'to', 'make', 'i', 'love', 'making', 'her', 'deserts', \"it's\", 'really', 'easy', 'she', 'talks', 'the', 'talks', 'and', 'walks', 'the', 'walks', 'i', 'mean', 'some', 'other', 'cooking', 'shows', 'the', 'ingredients', 'are', 'really', 'hard', 'to', 'find', 'but', 'ina', 'recipes', 'are', 'easy', 'and', 'great', 'i', 'mean', 'her', 'famous', 'roast', 'chicken', 'are', 'really', 'tasty', 'i', 'bought', 'her', 'book', 'about', '2', 'weeks', 'ago', 'and', 'the', 'recipes', 'are', 'easy', 'in', 'her', 'show', 'i', 'sometimes', 'like', 'to', 'cook', 'along', 'with', 'her', 'and', 'i', 'love', 'cooking', \"ina's\", 'show', 'makes', 'a', 'big', 'difference', 'for', 'new', 'people', 'who', 'are', 'trying', 'to', 'cook', 'watch', 'this', 'show', 'and', 'love', 'it', 'it', 'has', 'great', 'ideas', 'of', 'cooking', 'and', 'you', 'might', 'learn', 'something', 'new', 'like', 'i', 'learned', 'a', 'new', 'way', 'of', 'how', 'to', 'set', 'the', 'table', 'laugh', 'out', 'loud', 'but', 'the', 'point', 'is', 'she', 'is', 'a', 'great', 'host', 'a', 'chef', 'and', 'her', 'cooking', 'is', 'of', 'the', 'hook']\n"
     ]
    }
   ],
   "source": [
    "print([tokenizer.index_word.get(k, '<PAD>') for k in train_data[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-radius",
   "metadata": {},
   "source": [
    "# Train a classifier with Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "human-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_wiki = KeyedVectors.load('wiki-countries.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "honey-occasions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = utils.make_embedding_layer(countries_wiki, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "countries_wiki_model = Sequential([\n",
    "    Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32'),\n",
    "    embedding_layer,\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "countries_wiki_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "married-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1172/1172 [==============================] - 24s 21ms/step - loss: -16641.9727 - accuracy: 0.1667 - val_loss: 65643.5391 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1172/1172 [==============================] - 27s 23ms/step - loss: -225707.7031 - accuracy: 0.1667 - val_loss: 447620.6250 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1172/1172 [==============================] - 37s 32ms/step - loss: -828230.2500 - accuracy: 0.1667 - val_loss: 1270633.3750 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1172/1172 [==============================] - 50s 43ms/step - loss: -1917466.7500 - accuracy: 0.1667 - val_loss: 2608856.2500 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1172/1172 [==============================] - 43s 37ms/step - loss: -3549600.5000 - accuracy: 0.1667 - val_loss: 4510364.0000 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1172/1172 [==============================] - 30s 26ms/step - loss: -5783278.5000 - accuracy: 0.1667 - val_loss: 7038023.0000 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1172/1172 [==============================] - 30s 25ms/step - loss: -8691590.0000 - accuracy: 0.1667 - val_loss: 10272849.0000 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1172/1172 [==============================] - 31s 27ms/step - loss: -12336643.0000 - accuracy: 0.1667 - val_loss: 14257598.0000 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1172/1172 [==============================] - 29s 25ms/step - loss: -16778410.0000 - accuracy: 0.1667 - val_loss: 19058352.0000 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -22084874.0000 - accuracy: 0.1667 - val_loss: 24761140.0000 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "1172/1172 [==============================] - 35s 30ms/step - loss: -28339982.0000 - accuracy: 0.1667 - val_loss: 31435292.0000 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "1172/1172 [==============================] - 36s 30ms/step - loss: -35588056.0000 - accuracy: 0.1667 - val_loss: 39109404.0000 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "1172/1172 [==============================] - 31s 27ms/step - loss: -43863900.0000 - accuracy: 0.1667 - val_loss: 47811596.0000 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "1172/1172 [==============================] - 34s 29ms/step - loss: -53257640.0000 - accuracy: 0.1667 - val_loss: 57697140.0000 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -63865820.0000 - accuracy: 0.1667 - val_loss: 68784184.0000 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -75711872.0000 - accuracy: 0.1667 - val_loss: 81125408.0000 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -88845176.0000 - accuracy: 0.1667 - val_loss: 94777192.0000 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -103363848.0000 - accuracy: 0.1667 - val_loss: 109816328.0000 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "1172/1172 [==============================] - 32s 27ms/step - loss: -119283744.0000 - accuracy: 0.1667 - val_loss: 126276072.0000 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "1172/1172 [==============================] - 32s 27ms/step - loss: -136716848.0000 - accuracy: 0.1667 - val_loss: 144300400.0000 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "1172/1172 [==============================] - 32s 27ms/step - loss: -155722960.0000 - accuracy: 0.1667 - val_loss: 163854832.0000 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "1172/1172 [==============================] - 32s 27ms/step - loss: -176284048.0000 - accuracy: 0.1667 - val_loss: 184962816.0000 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "1172/1172 [==============================] - 31s 27ms/step - loss: -198497152.0000 - accuracy: 0.1667 - val_loss: 207794800.0000 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "1172/1172 [==============================] - 32s 27ms/step - loss: -222518048.0000 - accuracy: 0.1667 - val_loss: 232431136.0000 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -248399744.0000 - accuracy: 0.1667 - val_loss: 258972480.0000 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "1172/1172 [==============================] - 35s 30ms/step - loss: -276105984.0000 - accuracy: 0.1667 - val_loss: 287263168.0000 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "1172/1172 [==============================] - 41s 35ms/step - loss: -305662048.0000 - accuracy: 0.1667 - val_loss: 317435360.0000 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "1172/1172 [==============================] - 35s 30ms/step - loss: -337288928.0000 - accuracy: 0.1667 - val_loss: 349765856.0000 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "1172/1172 [==============================] - 33s 28ms/step - loss: -370958208.0000 - accuracy: 0.1667 - val_loss: 384041920.0000 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "1172/1172 [==============================] - 44s 37ms/step - loss: -406680032.0000 - accuracy: 0.1667 - val_loss: 420405952.0000 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "countries_wiki_history = countries_wiki_model.fit(\n",
    "    train_data, dfTrain['label'].values,\n",
    "    validation_data=(test_data, xts['label'].values),\n",
    "    batch_size=64, epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-jersey",
   "metadata": {},
   "source": [
    "# Train with a different set of word embeddings\n",
    "\n",
    "## GloVe: Global Vectors for Word Representation\n",
    "### Download [here](http://nlp.stanford.edu/data/glove.6B.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "voluntary-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_wiki = KeyedVectors.load_word2vec_format('data/glove.6B/glove.6B.300d.txt', binary=False, no_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "beginning-concert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = utils.make_embedding_layer(glove_wiki, tokenizer, MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "glove_model = Sequential([\n",
    "    Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32'),\n",
    "    embedding_layer,\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "glove_model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "identical-breath",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2344/2344 [==============================] - 81s 33ms/step - loss: -50649.3477 - accuracy: 0.1667 - val_loss: 184496.8906 - val_accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "2344/2344 [==============================] - 85s 36ms/step - loss: -566044.8125 - accuracy: 0.1667 - val_loss: 1068684.7500 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "2344/2344 [==============================] - 76s 32ms/step - loss: -1918321.1250 - accuracy: 0.1667 - val_loss: 2877956.5000 - val_accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "2344/2344 [==============================] - 75s 32ms/step - loss: -4323605.0000 - accuracy: 0.1667 - val_loss: 5836816.5000 - val_accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "2344/2344 [==============================] - 80s 34ms/step - loss: -8016980.5000 - accuracy: 0.1667 - val_loss: 10163823.0000 - val_accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "2344/2344 [==============================] - 83s 35ms/step - loss: -13169944.0000 - accuracy: 0.1667 - val_loss: 16015656.0000 - val_accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: -20012426.0000 - accuracy: 0.1667 - val_loss: 23654598.0000 - val_accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: -28770734.0000 - accuracy: 0.1667 - val_loss: 33268432.0000 - val_accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: -39600532.0000 - accuracy: 0.1667 - val_loss: 44991732.0000 - val_accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "2344/2344 [==============================] - 69s 29ms/step - loss: -52736648.0000 - accuracy: 0.1667 - val_loss: 59130552.0000 - val_accuracy: 0.5000\n",
      "Epoch 11/30\n",
      "2344/2344 [==============================] - 78s 33ms/step - loss: -68412664.0000 - accuracy: 0.1667 - val_loss: 75856912.0000 - val_accuracy: 0.5000\n",
      "Epoch 12/30\n",
      "2344/2344 [==============================] - 76s 33ms/step - loss: -86735552.0000 - accuracy: 0.1667 - val_loss: 95242024.0000 - val_accuracy: 0.5000\n",
      "Epoch 13/30\n",
      "2344/2344 [==============================] - 73s 31ms/step - loss: -108058864.0000 - accuracy: 0.1667 - val_loss: 117779864.0000 - val_accuracy: 0.5000\n",
      "Epoch 14/30\n",
      "2344/2344 [==============================] - 72s 31ms/step - loss: -132506200.0000 - accuracy: 0.1667 - val_loss: 143370016.0000 - val_accuracy: 0.5000\n",
      "Epoch 15/30\n",
      "2344/2344 [==============================] - 76s 33ms/step - loss: -160165152.0000 - accuracy: 0.1667 - val_loss: 172248944.0000 - val_accuracy: 0.5000\n",
      "Epoch 16/30\n",
      "2344/2344 [==============================] - 75s 32ms/step - loss: -191427376.0000 - accuracy: 0.1667 - val_loss: 204798768.0000 - val_accuracy: 0.5000\n",
      "Epoch 17/30\n",
      "2344/2344 [==============================] - 74s 32ms/step - loss: -226359504.0000 - accuracy: 0.1667 - val_loss: 241070832.0000 - val_accuracy: 0.5000\n",
      "Epoch 18/30\n",
      "2344/2344 [==============================] - 68s 29ms/step - loss: -265203296.0000 - accuracy: 0.1667 - val_loss: 281210496.0000 - val_accuracy: 0.5000\n",
      "Epoch 19/30\n",
      "2344/2344 [==============================] - 67s 29ms/step - loss: -308088864.0000 - accuracy: 0.1667 - val_loss: 325452800.0000 - val_accuracy: 0.5000\n",
      "Epoch 20/30\n",
      "2344/2344 [==============================] - 67s 29ms/step - loss: -355347392.0000 - accuracy: 0.1667 - val_loss: 374199872.0000 - val_accuracy: 0.5000\n",
      "Epoch 21/30\n",
      "2344/2344 [==============================] - 67s 29ms/step - loss: -407002880.0000 - accuracy: 0.1667 - val_loss: 427178944.0000 - val_accuracy: 0.5000\n",
      "Epoch 22/30\n",
      "2344/2344 [==============================] - 67s 29ms/step - loss: -463545408.0000 - accuracy: 0.1667 - val_loss: 485264896.0000 - val_accuracy: 0.5000\n",
      "Epoch 23/30\n",
      "2344/2344 [==============================] - 67s 29ms/step - loss: -524920672.0000 - accuracy: 0.1667 - val_loss: 548066752.0000 - val_accuracy: 0.5000\n",
      "Epoch 24/30\n",
      "2344/2344 [==============================] - 69s 30ms/step - loss: -591354880.0000 - accuracy: 0.1667 - val_loss: 615823040.0000 - val_accuracy: 0.5000\n",
      "Epoch 25/30\n",
      "2344/2344 [==============================] - 63s 27ms/step - loss: -663010240.0000 - accuracy: 0.1667 - val_loss: 689036928.0000 - val_accuracy: 0.5000\n",
      "Epoch 26/30\n",
      "2344/2344 [==============================] - 60s 25ms/step - loss: -740288000.0000 - accuracy: 0.1667 - val_loss: 767898048.0000 - val_accuracy: 0.5000\n",
      "Epoch 27/30\n",
      "2344/2344 [==============================] - 60s 26ms/step - loss: -823263232.0000 - accuracy: 0.1667 - val_loss: 852279872.0000 - val_accuracy: 0.5000\n",
      "Epoch 28/30\n",
      "2344/2344 [==============================] - 60s 26ms/step - loss: -912188800.0000 - accuracy: 0.1667 - val_loss: 942704448.0000 - val_accuracy: 0.5000\n",
      "Epoch 29/30\n",
      "2344/2344 [==============================] - 60s 25ms/step - loss: -1007166592.0000 - accuracy: 0.1667 - val_loss: 1039149120.0000 - val_accuracy: 0.5000\n",
      "Epoch 30/30\n",
      "2344/2344 [==============================] - 60s 25ms/step - loss: -1108177024.0000 - accuracy: 0.1667 - val_loss: 1141446528.0000 - val_accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "glove_history = glove_model.fit(\n",
    "    train_data, dfTrain['label'].values,\n",
    "    validation_data=(test_data, xts['label'].values),\n",
    "    batch_size=32, epochs=30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "interior-season",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fee68cbff10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(countries_wiki_history.history['val_accuracy'], label='Countries Wiki')\n",
    "plt.plot(glove_history.history['val_accuracy'], label='All Wiki')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-universe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
